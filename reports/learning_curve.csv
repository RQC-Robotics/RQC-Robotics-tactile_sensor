train_loss,test_loss
0.15258412844604916,0.13496767312288285
0.10834175258874894,0.09033516198396682
0.08394500932759709,0.08069853276014329
0.07833522147602505,0.07681338608264923
0.07521032869815826,0.07385223329067231
0.07223293892211384,0.07117518439888953
0.07026820336778959,0.06982193008065224
0.06837929179271063,0.06740136384963989
0.06681593270765411,0.06654525101184845
0.06607559118005965,0.06594201475381851
0.06553317636251449,0.06542169257998466
0.06487321156594489,0.06445385679602623
0.06395116936829355,0.0638225944340229
0.06346845314734512,0.06343392051756382
0.06309324507084157,0.06307897686958314
0.06271611367662748,0.06271336175501346
0.06221137656933731,0.06206360749900341
0.061703702153431045,0.06164832249283791
0.06134655264516672,0.06136271230876446
0.06103477548393938,0.06092449106276035
0.06045892966290315,0.060407303422689435
0.059902109089824886,0.05967178836464882
0.05930748412178622,0.059211034923791886
0.0588482462366422,0.058758086785674096
0.05847152616414759,0.05846155531704426
0.058219751252068415,0.05827017195522785
0.058036464899778366,0.05809893548488617
0.057858641172448794,0.057924615740776064
0.057687628376815056,0.05776857279241085
0.057346259959869916,0.05723124422132969
0.05690923643608888,0.05685458607971668
0.05661397003465229,0.05671085953712463
0.056460544847779806,0.056493019536137584
0.05622913423511717,0.056345706805586815
0.05592901249726613,0.05594295635819435
0.0556807003584173,0.055816942304372785
0.05544448292917675,0.055538056194782255
0.05526378028922611,0.055424444824457166
0.055145505021015805,0.055322390422225
0.05503276087343693,0.05522278390824795
0.05492514852848318,0.055127670839428905
0.054822452126277815,0.05503734201192856
0.05472256829341253,0.05494770586490631
0.05462695471942425,0.05486325815320015
0.05453459011183845,0.054779693707823755
0.05444449139138063,0.054699926897883416
0.05435692807866467,0.05461910158395767
0.05427293377617995,0.05454565070569515
0.05418921838204066,0.05447409376502037
0.05410870288809141,0.0544055338203907
