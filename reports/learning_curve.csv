train_loss,test_loss
0.060160795818818245,0.051327534317970276
0.04145846741764169,0.03915300913155079
0.03748512319044063,0.03698596581816673
0.03567758691546164,0.0359267695993185
0.034595486617794165,0.03472550056874752
0.03379633735865355,0.033977728188037876
0.03316002554799381,0.03354715555906296
0.03263653375992649,0.03323761396110058
0.032176053108353364,0.033007698953151705
0.03176506313054185,0.032527836486697194
0.03140221038931294,0.032309023290872575
0.031072775523521397,0.032272315174341204
0.030762680966995266,0.031910479329526426
0.030450834839751847,0.03165379013866186
0.030163089487897723,0.03153789211064577
0.02992295063051738,0.03118506345897913
0.029660199421801065,0.03109587147831917
0.029434007621909442,0.03115516733378172
0.029251244309309282,0.03100618451833725
0.02903537747107054,0.03071223173290491
0.02880221059055705,0.03048551857471466
0.02859573926188444,0.030383679158985613
0.02842013668661055,0.03042351394891739
0.028250892999532977,0.03015728883445263
0.028077548787389932,0.030227223709225655
0.027860539379088504,0.030006969906389715
0.027741218464154945,0.029999799579381942
0.027598670862222972,0.029810948520898817
0.02739720388854805,0.029678169339895248
0.027244166361266062,0.029652467593550683
0.027080881421111133,0.02969264976680279
0.026933679296390005,0.02972948186099529
0.026817923248990586,0.029620998091995716
0.026656776190196213,0.029427282884716986
0.026493054334270325,0.029285447113215922
0.026418328306784755,0.029236741922795774
0.0262320021402679,0.029066890515387057
0.026166839860379695,0.029261855259537697
0.025995523615887292,0.029170135334134102
0.02586603288979907,0.02905878659337759
