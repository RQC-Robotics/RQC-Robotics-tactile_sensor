{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/korbash/projects/torch_sensor_gpu/sashas_net\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import sensor_lib as sl\n",
    "import sensor_lib.data_analis as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellId": "p5k153ekggp9r7wh6i7ej6",
    "id": "EPNxeZi7MnUO"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join as jn\n",
    "import yaml\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('params.yaml') as conf_file:\n",
    "    config = yaml.safe_load(conf_file)\n",
    "geo = config['env']['sen_geometry']\n",
    "phys = config['env']['phys']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(config['random_seed'])\n",
    "seeds = np.random.randint(0, 2**32, size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "0qsaltjhgqjacye7rpbjuj6",
    "id": "nlRUT4zvYX8n"
   },
   "source": [
    "# generation pressure_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-11 14:39:29.021439: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-11 14:39:29.881502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1162 MB memory:  -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:8b:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "x = geo['x_len']\n",
    "y = geo['y_len']\n",
    "n_pic = config['dataset']['n_sampels']\n",
    "n_gaus = config['env']['presure_profile']['n_gauses']\n",
    "size_kof = config['env']['presure_profile']['size_kof']\n",
    "vec_mat = tf.constant(sl.get_vec_mat(x, y), dtype=tf.float32)\n",
    "vec_mat = tf.reshape(vec_mat, [-1, 2])\n",
    "gaus_data = sl.gen_rand_cof(n_gaus * n_pic, x, y, size_kof,\n",
    "                            seed=seeds[0])  # use random inside\n",
    "gaus_data = tf.reshape(gaus_data, [n_pic, n_gaus, 5])\n",
    "with open(config['env']['presure_profile']['g_param_path'], 'wb+') as f:\n",
    "    np.save(f, gaus_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(gaus_data)\n",
    "batches = dataset.batch(config['gengaus']['batch_size'], drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf.profiler.experimental.start('logs')\n",
    "pictures=[]\n",
    "for batch in batches:\n",
    "    picture = sl.generate_pictures(batch, vec_mat)\n",
    "    pictures.append(picture)\n",
    "tf.profiler.experimental.stop()\n",
    "pictures = tf.concat(pictures, axis=0)\n",
    "pictures = tf.reshape(pictures, [n_pic, x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer = tf.summary.create_file_writer('logs')\n",
    "# tf.summary.trace_on(graph=True, profiler=True)\n",
    "# pic = sl.generate_multi_gaussian_flat(gaus_data[0], vec_mat)\n",
    "# with writer.as_default():\n",
    "#     tf.summary.trace_export(\n",
    "#       name=\"multi_gaussian_trace\",\n",
    "#       step=0,\n",
    "#       profiler_outdir='logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pictures.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "limit by hat fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = sl.round_fun([x, y], [x / 2, y / 2], lambda l: sl.hat(l, x / 2))\n",
    "pictures = pictures * norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.imshow(pictures[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(jn(config['dataset']['pic_path'], 'one_piece.npy'), 'wb+') as f:\n",
    "    np.save(f, pictures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "1ntrxij2ivueoga583gl08",
    "id": "1S5uLr7FZMqo"
   },
   "source": [
    "# counting losses in fibers (input of nerual network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    size = None\n",
    "    max_possible_size = config['sim']['max_possible_size']\n",
    "    test_size = config['sim']['test_size']\n",
    "    batch_size = config['sim']['batch_size']\n",
    "    n_del = geo['n_spl']\n",
    "    mas = np.load(jn(config['dataset']['pic_path'],'one_piece.npy'), mmap_mode='r')\n",
    "    if size == None:\n",
    "        size = min(mas.shape[0], max_possible_size)\n",
    "    if test_size == 'None':\n",
    "        test_size = int(size / 10)\n",
    "    mas = mas[0:size]\n",
    "    mas = mas.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 64, 64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['sim']['test_mod'] = False\n",
    "input, output, input_test, output_test = sl.sim_on_gpu(\n",
    "    mas, test_size, batch_size, config=config,\n",
    "    seed=seeds[1])  # use random inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 64, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "nkd72ry4zcavf15haxeacf",
    "id": "2HBUJ_mMZzqT"
   },
   "source": [
    "# defining nerual network for decoding and fitting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  (899990, 64, 4) \n",
      "output shape:  (899990, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "print('input shape: ', input.shape, '\\noutput shape: ', output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellId": "cweyh603iwrectff9dywgi",
    "id": "BDLRQfkvWuX7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64, 4)]      0           []                               \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 64, 4, 1)     0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " Conv_1.1 (Conv2D)              (None, 64, 4, 8)     32          ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " MaxPool_1.1 (MaxPooling2D)     (None, 32, 4, 8)     0           ['Conv_1.1[0][0]']               \n",
      "                                                                                                  \n",
      " normalization (Normalization)  (None, 32, 4, 8)     3           ['MaxPool_1.1[0][0]']            \n",
      "                                                                                                  \n",
      " Conv_1.2 (Conv2D)              (None, 32, 4, 64)    1600        ['normalization[0][0]']          \n",
      "                                                                                                  \n",
      " MaxPool_1.2 (MaxPooling2D)     (None, 16, 4, 64)    0           ['Conv_1.2[0][0]']               \n",
      "                                                                                                  \n",
      " normalization_1 (Normalization  (None, 16, 4, 64)   3           ['MaxPool_1.2[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " MaxPool_1.0 (MaxPooling2D)     (None, 16, 4, 8)     0           ['Conv_1.1[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 16, 4, 72)    0           ['normalization_1[0][0]',        \n",
      "                                                                  'MaxPool_1.0[0][0]']            \n",
      "                                                                                                  \n",
      " Conv_2.1 (Conv2D)              (None, 16, 4, 128)   27776       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " MaxPool_2.1 (MaxPooling2D)     (None, 8, 4, 128)    0           ['Conv_2.1[0][0]']               \n",
      "                                                                                                  \n",
      " normalization_2 (Normalization  (None, 8, 4, 128)   3           ['MaxPool_2.1[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " Conv_2.2 (Conv2D)              (None, 8, 4, 128)    49280       ['normalization_2[0][0]']        \n",
      "                                                                                                  \n",
      " MaxPool_2.2 (MaxPooling2D)     (None, 4, 4, 128)    0           ['Conv_2.2[0][0]']               \n",
      "                                                                                                  \n",
      " MaxPool_2.0 (MaxPooling2D)     (None, 4, 4, 72)     0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 4, 4, 200)    0           ['MaxPool_2.2[0][0]',            \n",
      "                                                                  'MaxPool_2.0[0][0]']            \n",
      "                                                                                                  \n",
      " Conv_3 (Conv2D)                (None, 4, 1, 64)     51264       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 256)          0           ['Conv_3[0][0]']                 \n",
      "                                                                                                  \n",
      " Dense_4 (Dense)                (None, 195)          50115       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " Dense_5 (Dense)                (None, 900)          176400      ['Dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " Dense_6 (Dense)                (None, 4096)         3690496     ['Dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 64, 64)       0           ['Dense_6[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,046,972\n",
      "Trainable params: 4,046,963\n",
      "Non-trainable params: 9\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tr = config['train']\n",
    "model = sl.SensorNN5S_norm_deep(input.shape, output.shape)\n",
    "model.build(input.shape)\n",
    "model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(tr['lerning_rate']),\n",
    "              loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=['accuracy'])\n",
    "model_name = 'SensorNN5S_norm_deep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellId": "lfkb5a64nuo5099uzvu1sc",
    "id": "kmGd-a3SW0j6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-11 16:54:46.600627: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 14745436160 exceeds 10% of free system memory.\n",
      "2022-06-11 16:55:08.669678: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 14745436160 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1800/1800 [==============================] - 24s 10ms/step - loss: 0.3486 - accuracy: 0.0470\n",
      "Epoch 2/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2691 - accuracy: 0.0524\n",
      "Epoch 3/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2463 - accuracy: 0.0593\n",
      "Epoch 4/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2400 - accuracy: 0.0618\n",
      "Epoch 5/50\n",
      "1800/1800 [==============================] - 17s 10ms/step - loss: 0.2356 - accuracy: 0.0639\n",
      "Epoch 6/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2326 - accuracy: 0.0658\n",
      "Epoch 7/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2304 - accuracy: 0.0673\n",
      "Epoch 8/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2287 - accuracy: 0.0687\n",
      "Epoch 9/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2272 - accuracy: 0.0698\n",
      "Epoch 10/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2260 - accuracy: 0.0708\n",
      "Epoch 11/50\n",
      "1800/1800 [==============================] - 17s 10ms/step - loss: 0.2248 - accuracy: 0.0718\n",
      "Epoch 12/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2238 - accuracy: 0.0726\n",
      "Epoch 13/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2229 - accuracy: 0.0735\n",
      "Epoch 14/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2220 - accuracy: 0.0743\n",
      "Epoch 15/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2212 - accuracy: 0.0752\n",
      "Epoch 16/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2205 - accuracy: 0.0759\n",
      "Epoch 17/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2198 - accuracy: 0.0766\n",
      "Epoch 18/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2191 - accuracy: 0.0773\n",
      "Epoch 19/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2185 - accuracy: 0.0780\n",
      "Epoch 20/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2179 - accuracy: 0.0787\n",
      "Epoch 21/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2173 - accuracy: 0.0793\n",
      "Epoch 22/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2168 - accuracy: 0.0800\n",
      "Epoch 23/50\n",
      "1800/1800 [==============================] - 17s 10ms/step - loss: 0.2162 - accuracy: 0.0806\n",
      "Epoch 24/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2158 - accuracy: 0.0812\n",
      "Epoch 25/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2153 - accuracy: 0.0817\n",
      "Epoch 26/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2148 - accuracy: 0.0822\n",
      "Epoch 27/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2144 - accuracy: 0.0828\n",
      "Epoch 28/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2140 - accuracy: 0.0833\n",
      "Epoch 29/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2136 - accuracy: 0.0838\n",
      "Epoch 30/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2132 - accuracy: 0.0843\n",
      "Epoch 31/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2128 - accuracy: 0.0847\n",
      "Epoch 32/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2125 - accuracy: 0.0852\n",
      "Epoch 33/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2121 - accuracy: 0.0856\n",
      "Epoch 34/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2118 - accuracy: 0.0861\n",
      "Epoch 35/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2115 - accuracy: 0.0864\n",
      "Epoch 36/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2112 - accuracy: 0.0868\n",
      "Epoch 37/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2109 - accuracy: 0.0872\n",
      "Epoch 38/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2106 - accuracy: 0.0876\n",
      "Epoch 39/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2103 - accuracy: 0.0879\n",
      "Epoch 40/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2100 - accuracy: 0.0883\n",
      "Epoch 41/50\n",
      "1800/1800 [==============================] - 17s 10ms/step - loss: 0.2097 - accuracy: 0.0887\n",
      "Epoch 42/50\n",
      "1800/1800 [==============================] - 17s 10ms/step - loss: 0.2094 - accuracy: 0.0890\n",
      "Epoch 43/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2091 - accuracy: 0.0894\n",
      "Epoch 44/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2089 - accuracy: 0.0897\n",
      "Epoch 45/50\n",
      "1800/1800 [==============================] - 17s 10ms/step - loss: 0.2086 - accuracy: 0.0900\n",
      "Epoch 46/50\n",
      "1800/1800 [==============================] - 17s 10ms/step - loss: 0.2084 - accuracy: 0.0904\n",
      "Epoch 47/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2081 - accuracy: 0.0907\n",
      "Epoch 48/50\n",
      "1800/1800 [==============================] - 17s 10ms/step - loss: 0.2079 - accuracy: 0.0911\n",
      "Epoch 49/50\n",
      "1800/1800 [==============================] - 17s 10ms/step - loss: 0.2077 - accuracy: 0.0914\n",
      "Epoch 50/50\n",
      "1800/1800 [==============================] - 18s 10ms/step - loss: 0.2074 - accuracy: 0.0917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f24c02ca160>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(dataset_b, epochs=n_epochs, verbose=1)\n",
    "tf.keras.utils.set_random_seed(seed=int(seeds[2]))  # use random\n",
    "model.fit(input, output, epochs=tr['n_epochs'], verbose=1, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellId": "xyvoz6f4edtsir4vw4mbo",
    "id": "yn0PxjqHW5Mj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/SensorNN5S_norm_deep.nn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/SensorNN5S_norm_deep.nn/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(jn(tr['models_path'], model_name + '.nn'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "5m68q6aecufkzhregwm9",
    "id": "59CcWzTRao6i"
   },
   "source": [
    "# evoluate model on don't seen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = config['evaluate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(899990, 64, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "hp908y5rqlnqmj0rwdk7og",
    "id": "3EJRgZf_ahn8"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(jn(tr['models_path'], model_name + '.nn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellId": "sryew8rev5sk0fxhof1fad",
    "id": "5f1CsIn2W-mx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step - loss: 0.2131 - accuracy: 0.0755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-11 17:11:14.055898: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 14745436160 exceeds 10% of free system memory.\n",
      "2022-06-11 17:11:28.399054: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 14745436160 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28125/28125 [==============================] - 106s 4ms/step - loss: 0.2075 - accuracy: 0.0910\n"
     ]
    }
   ],
   "source": [
    "test = model.evaluate(input_test, output_test)\n",
    "train = model.evaluate(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['loss','accuracy']\n",
    "test_d = dict(zip(keys, test))\n",
    "train_d = dict(zip(keys, train))\n",
    "res = {'train': train_d, 'test': test_d}\n",
    "with open(jn(ev['reports_path'], \"summary.json\"), \"w\") as f:\n",
    "    json.dump(res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellId": "0mjlepsq9t4ky98kcqoh8zd",
    "id": "u7JN832XXD8w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 64, 64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(input_test)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "rbse2nlcd3h9f0nucbc1tf",
    "id": "Dosd971-bpeh"
   },
   "source": [
    "# saving resalts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "yggb3i363hppnsz5id8yi",
    "id": "exK4-QIhXG7C"
   },
   "outputs": [],
   "source": [
    "with open(jn(ev['pred_path'], 'pred.npy'), 'wb') as f:\n",
    "    np.save(f, predictions)\n",
    "with open(jn(ev['pred_path'], 'true.npy'), 'wb') as f:\n",
    "    np.save(f, output_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "fc135ka0qptz32k3d3n7xf",
    "id": "SoeWHe4obu1u"
   },
   "source": [
    "# look on resalts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sensor_lib.data_analis as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_true= jn(ev['pred_path'], 'true.npy')\n",
    "# path_pred= jn(ev['pred_path'], 'pred.npy')\n",
    "# inter=(81000,90000)\n",
    "# l=100000\n",
    "# n_ga_mas=[15,30]\n",
    "# n_fi_mas=[1,2,3,4,8,16]\n",
    "# dic=ds.get_dic(n_ga_mas,n_fi_mas, path_true, path_pred, l, inter)\n",
    "# df=pd.DataFrame(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "zmrk4xfth886cjwbb72pza",
    "id": "R90KNoG0b4oi"
   },
   "outputs": [],
   "source": [
    "with open(jn(ev['pred_path'], 'pred.npy'), 'rb') as f:\n",
    "    predictions = np.load(f)\n",
    "with open(jn(ev['pred_path'], 'true.npy'), 'rb') as f:\n",
    "    output_test = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 0\n",
    "fig, axes = plt.subplots(1, 2, squeeze=True)\n",
    "axes[0].imshow(predictions[N])\n",
    "axes[0].set_title('pred')\n",
    "axes[1].imshow(output_test[N])\n",
    "axes[1].set_title('true')\n",
    "fig.set_figwidth(5 * 2)\n",
    "fig.set_figheight(5)\n",
    "fig.savefig(jn(ev['reports_path'], 'result_sampel.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "dtz68v8jwn6pwttc1nbag",
    "id": "T22TeQF6XJ9i"
   },
   "outputs": [],
   "source": [
    "print('len= ', len(predictions))\n",
    "N = 710 # number of exampel\n",
    "fig = plt.imshow(predictions[N])\n",
    "fig.savefig(jn(ev['report_path'],'result_sampel', 'pred.png'))\n",
    "plt.show()\n",
    "fig = plt.imshow(output_test[N])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Untitled11.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "interpreter": {
   "hash": "e99257ad9e10e3258445396f20cee2b0bc7a8bf63881ff00d850e5c9ea0323e9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venvPytorchAndTF': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "notebookId": "481d3098-b4e4-4dca-8695-2093b7f3dc4c",
  "notebookPath": "RQC-Robotics-tactile_sensor/exampels/main.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
