{"cells":[{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/amir/rqc_internship/sensor_repo\n"]}],"source":["\n","from pathlib import Path\n","import sys\n","import os\n","\n","# path_root = Path(__file__).parents[1]\n","# sys.path.append(str(path_root))\n","# os.chdir('..')\n","%cd ..\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from os.path import join as jn\n","import yaml\n","\n","import torch\n","from torch.utils.data import DataLoader\n","from tqdm.notebook import tqdm\n","import json\n","\n","from video_module import Stack_dataset, \\\n","    fit_epoch, eval_epoch, predict, eval_dataset"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["with open('params.yaml') as conf_file:\n","    config = yaml.safe_load(conf_file)\n","with open('pathes.yaml') as conf_file:\n","    path_config = yaml.safe_load(conf_file)\n","\n","if not os.path.exists(path_config['reports_path']):\n","    os.makedirs(path_config['reports_path'])"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["torch.manual_seed(config['random_seed'])\n","np.random.seed(config['random_seed'])\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                         \r"]}],"source":["\n","input_path = path_config['train_s_video_path']\n","test_input_path = path_config['test_s_video_path']\n","output_path = path_config['p_video_path']\n","\n","tr = config['video_train']\n","frames_number, frames_interval = tr[\"frames_number\"], tr[\"frames_interval\"]\n","\n","test_dataset = Stack_dataset(output_path, test_input_path, frames_number,\n","                             frames_interval)\n","train_dataset = Stack_dataset(output_path, input_path, frames_number,\n","                              frames_interval)\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CUDA is NOT available.  Training on CPU ...\n"]}],"source":["\n","if not torch.cuda.is_available():\n","    print('CUDA is NOT available.  Training on CPU ...')\n","else:\n","    print('CUDA is available!  Training on GPU ...')\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","signal_shape, pressure_shape = (x.shape for x in train_dataset[0])\n","print('input chain shape: ', signal_shape, '\\noutput chain shape: ',\n","      pressure_shape)\n","\n","model_name = tr['model_name']\n","import models_src\n","\n","model_class = eval(f\"models_src.{model_name}\")\n","\n","args = []\n","if model_name.startswith(\"Param\"):\n","    layers = tr['layers']\n","    args.append(layers)\n","args.append(frames_number)\n","args.append(frames_interval)\n","model = model_class(pressure_shape[-2:], signal_shape[-2:], *args)\n","model = model.to(device)\n","\n","# print(model)\n","optim = torch.optim.Adam(model.parameters(), lr=tr['learning_rate'])\n","loss_fn = torch.nn.MSELoss()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","def iter_train(train_dataset, test_dataset, model, epochs, optimizer,\n","               criterion):\n","    for epoch in range(epochs):\n","        train_loss = fit_epoch(model, train_dataset, criterion, optimizer,\n","                               tr['batch_size'], device)\n","        test_loss = eval_epoch(model, test_dataset, criterion,\n","                               config['test_batch_size'], device)\n","        # print(\"loss\", f\"{train_loss:.3f}\")\n","        # pbar.set_postfix(train_loss=train_loss, test_loss=test_loss)\n","        # full_train_loss = eval_dataset(model, train_dataset, criterion, config['test_batch_size'], device)\n","        # full_test_loss = eval_dataset(model, test_dataset, criterion, config['test_batch_size'], device)\n","        yield (train_loss, test_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["history = []"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["epochs = config['video_train']['epochs']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with tqdm(total=epochs,\n","          position=0,\n","          unit='epoch',\n","          desc=\"Learning\",\n","          dynamic_ncols=True) as pbar:\n","    \n","    for h in iter_train(train_dataset, test_dataset, model, epochs, optim,\n","                        loss_fn):\n","        history.append(h)\n","        train_loss, test_loss = h\n","        # print(f\"Epoch {i+1}/{total_epochs}\",\n","        #       f\"train loss: {full_train_loss:.5f}, test_loss: {full_test_loss:.5f}\")\n","        pbar.update()\n","        pbar.set_postfix(train_loss=train_loss, test_loss=test_loss)\n","\n","        titles = [\"full_train_loss\", \"full_test_loss\"]\n","        res = np.array([titles] + history)\n","        for j, title in enumerate(titles):\n","            np.savetxt(jn(path_config['reports_path'], title + '.csv'),\n","                        res[:, j],\n","                        delimiter=',',\n","                        fmt='%s')\n","\n","        os.system('dvc plots show -q')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["full_train_loss, full_test_loss = zip(*history)\n","res = {\n","    'train': {\n","        'loss': full_train_loss[np.argmin(full_test_loss)]\n","    },\n","    'test': {\n","        'loss': min(full_test_loss)\n","    }\n","}\n","with open(jn(path_config['reports_path'], \"v_summary.json\"), \"w\") as f:\n","    json.dump(res, f)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python csv_logger.py"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if not os.path.exists(path_config['v_model_path']):\n","    os.makedirs(path_config['v_model_path'])\n","torch.save(model, jn(path_config['v_model_path'], model_name + '.pt'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from video_module import Dynamic_video_dataset, predict, visual_chains\n","\n","v_model = model\n","\n","save_path = path_config['video_predict_vis_path']\n","if not os.path.exists(save_path):\n","    os.makedirs(save_path)\n","\n","\n","def visual_dataset(dataset, step, max_items, begin=0):\n","    prev_id = ''\n","    total=min(len(dataset.files) // step, max_items)\n","    for pressure, signal, file_name in tqdm(\n","            zip(dataset.pressure[:total*step:step], dataset.signal[:total*step:step],\n","                dataset.files[:total*step:step]), total=total):\n","        file_name = file_name[:-4]\n","        id = file_name[:file_name.rfind('/')]\n","        id = id[:id.rfind('/')]\n","        if id != prev_id:\n","            print(f\"\\n#### id = {id}\", file=file)\n","            prev_id = id\n","        prediction = predict(v_model,\n","                             signal[begin:],\n","                             device)\n","        pressure = pressure[-prediction.shape[0]:]\n","        visual_chains([pressure, prediction],\n","                      jn(save_path, file_name.replace('/', '_')))\n","        print(f\"<img src={file_name.replace('/', '_')+'.gif'} width=400>\",\n","              file=file)\n","\n","\n","\n","file = open(jn(save_path, \"view.md\"), 'w')\n","print(\"# Visualization\", file=file)\n","\n","# pred_test_dataset = Dynamic_video_dataset(output_path, test_input_path)\n","pred_test_dataset = test_dataset\n","print(\"# Test dataset\", file=file)\n","visual_dataset(pred_test_dataset, **config['visual']['test'])\n","\n","file.close()"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12 ('rqc_env')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"22975e861a4488f94634044a20ded97cfffd19315dfee221a4082522e37b8267"}}},"nbformat":4,"nbformat_minor":2}
