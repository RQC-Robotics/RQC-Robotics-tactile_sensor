# Документация, спецификация, контракты
---
---

для модуля предсказания профиля давления по сенсору с последовательности сигналов(видео)

## Раньше модели были устроены так:
в качестве аргументов forward принимает 3 тензора
**(карта давлений на предыдущем шаге, сигнал на предыдущем шаге, сингал на текущем шаге)**

**(predictions[i-1], signals[i-1], signals[i])**

Каждый тензор может быть тензором из таких элементов.
Все эврика вроде производной сигналов, логарифмов пропускания, применение наивной модели к каждому из сигналов, хоть выкидывание всего, кроме текущего сигнала будет реализовываться внутри модели. Такой интерфейс позволяет любое поведение реализовать.

## Сейчас модели:
в качестве аргументов инициализации принимают
**pressure_shape, signal_shape, hidden_layers: list[int], frames_number, frames_interval**
аргумент layers используется только если название начинается с Param. 
forward принимает тензор формы (batch_size, frame_numbers, signal_shape)

Сети должны содержать поля frames_number и frames_interval, чтобы функция predict могла правильно их запускать без дополнительных аргументов.

Рекурентность будет реализована просто функцией reset_memory, которая будет в начале вызываться, если она реализована.

## Обучение
Обучение должно происходить тоже на последовательности кадров разной длины. Для этого существует сущность **subdataloader**, которая инициализируется несколькими последовательностями кадров (chain-ами) и которая для каждого запуска модели формирует батч, описанный в пункте про модели.

Все данные будут храниться в формате видеороликов и соответствующих им файлов с последовательностями сигналов.
Датасет цепочек разной длины из этих видео (**video_dataset**) будет инициализироваться названиями файлов. Также содержит функцию для для разделения всех видеозаписей из обучающей выборки на последовательности длины **chain_len**. 
После запуска такой функции, по нему можно будет итерироваться с помощью torch.Dataloader и получить batch_size цепочек, передать их sub_dataloader-у, который уже по batch_size кадров будет передавать это модели, группируя данные в тот формат, под который специализируются модели.

## Dynamic_video_dataset
При создании нужно указать путь к папке с видео и с сигналами соответствующими. За видео принимает все файлы в папке и рекурентно подпапках. 
Нужен для быстрой работы с маленькой частью большого датасета. На загружает из памяти все файлы сразу, но имеет атрибуты **pressure** и **signal**, которые поддерживают обращение по индексу и срезы.

Поддерживает функцию **split_to_chains(chain_len)** которая сохраняет массив из псеводоуказателей на массивы.
Для каждой цепи подгружает целое видео в оперативную память, а не загрузить сразу все видео.

После использования функции split_to_chains будет доступно обращение по индексу к конкретной цепочке. Как загружается пара (цепочка, сигнал с цепочки)

## Video_dataset

Версия датасета, которая загружает при инициализации все данные в оперативную память и дальше использует ее оттуда.

Поддерживает функцию **split_to_chains(chain_len)** которая сохраняет массив из псеводоуказателей на массивы.


После использования функции split_to_chains будет доступно обращение по индексу к конкретной цепочке. Так загружается пара (цепочка, сигнал с цепочки)

Начиная примерно с коммита e25f0e1f311 + 4 делит на цепочки с пересечением по первому кадру. **chain_len** все еще равно длине выдаваемой цепочки. Это нужно для обучения нейросетей без рекуррентности с **chain_len** = 2. Тогда обучение будет происходить не на половине массива, а на почти всем (за исключением первого кадра для которого предыдущий сигнал не существует)

## Subdataloader

Инициализируется несколькими последовательностями кадров (chain-ами)\
(тензором **(batch_size, chain_len, signals_shape)**) 


для каждого запуска модели формирует батч, описанный в пункте про модели. \
**(predictions[i-1], signals[i-1], signals[i])** Где каждый элемент - массив длиной batch_size
Для этого после каждого вызова функцией **get_next_batch** батча из subdataloader-а нужно функцией **set_previous_pressure** передать результат работы модели, чтобы он был засунут в следующий батч.


# Функции для работы с моделями
## predict
(модель, последовательности сигналов в формате numpy)
(опционально начальные карты давлений для каждого chain-а, по умолчанию будут нули)
Тут инициализируется subdataloader и без градиентов по одному счатаются все новые и новые кадры. Потом конкатенируются и возвращается numpy массив.

## fit_epoch
(модель, video_dataset, criterion, optimizer, chain_len, batch_size)\
Запускает даталоадер по video_dataset, и с каждым input-ом из батча chain-ов запускает функцию **predict_chain_batch**, но только начиная со второго сигнала. А первое давление из каждой цепи сообщается функции predict_chain_batch. Потом сравнивает с помощью критерия с output-ом из батча и делает шаг оптимизатора.

## predict_chain_batch 
(модель, chain_batch, initial_pressure)\
очень похоже на predict, но другое назначение, так что пусть будет чуть-чуть копипасты.

создает subdataloader по chain_batch и правильным образом по ней итерируется. Возвращает конкатенированные давления.


## eval_video

запускает видео через sub-dataloader и возвращает лосс на одном видео.
Нужна, чтобы понимать с какими видео проблемы.
(можно обойтись следующей с video dataset из одного видео, но тогда придется руками подбирать chain_len)

## eval_epoch
принимает test_video_dataset и считает лосс с заданным chain_len

## eval_dataset
берет video_dataset и считает лосс по каждому видео. Возвращает среднее значение.
 